{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset do GIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Imagens_Resized.zip\n",
      "Extracted C:/content/Dataset2rotulos/Imagens_Resized.zip to C:/content\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import git\n",
    "\n",
    "# Define paths\n",
    "repo_url = \"https://github.com/vitor10102002/Dataset2rotulos.git\"\n",
    "download_path = \"C:/content/Dataset2rotulos\"\n",
    "zip_file_path = \"C:/content/Dataset2rotulos/Imagens_Resized.zip\"\n",
    "extract_path = \"C:/content\"\n",
    "\n",
    "# Clone the repository\n",
    "if os.path.exists(download_path):\n",
    "    try:\n",
    "        shutil.rmtree(download_path)  # Remove the existing folder if any\n",
    "    except:\n",
    "        print(\"\")\n",
    "\n",
    "git.Repo.clone_from(repo_url, download_path)\n",
    "\n",
    "# Check if the file exists in the cloned repo\n",
    "if os.path.exists(zip_file_path):\n",
    "    print(\"Found Imagens_Resized.zip\")\n",
    "else:\n",
    "    print(\"Imagens_Resized.zip not found in the repository.\")\n",
    "\n",
    "# Optionally, unzip the file\n",
    "if os.path.exists(zip_file_path):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "    print(f\"Extracted {zip_file_path} to {extract_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr√©-processamento das imagens com o r√≥tulo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Aplicar pr√©-processamentos nas imagens:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    resized_image = cv2.resize(image, (224, 224))\n",
    "\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontradas 105 imagens M1 para processamento...\n",
      "‚úÖ Processamento conclu√≠do!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Diret√≥rio das imagens originais e processadas\n",
    "image_folder = \"C:\\\\content\\\\out_resized\"\n",
    "output_folder = \"C:\\\\content\\\\processadas\\\\rotulo_M1\"\n",
    "\n",
    "# Criar pasta de sa√≠da se n√£o existir\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Listar arquivos na pasta e filtrar apenas os que come√ßam com \"M1_\"\n",
    "image_files = [f for f in os.listdir(image_folder) if f.startswith(\"M1_\") and f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "print(f\"Encontradas {len(image_files)} imagens M1 para processamento...\")\n",
    "\n",
    "for filename in image_files:\n",
    "    image_path = os.path.join(image_folder, filename)\n",
    "\n",
    "    # Ler a imagem\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Erro ao carregar {filename}, pulando...\")\n",
    "        continue\n",
    "\n",
    "    # üîπ Pr√©-processamento\n",
    "    processed_image = preprocess_image(image)\n",
    "\n",
    "    # Criar um novo nome para evitar sobrescrita\n",
    "    new_filename = f\"processada_{filename}\"\n",
    "    save_path = os.path.join(output_folder, new_filename)\n",
    "\n",
    "    # Salvar a imagem processada\n",
    "    cv2.imwrite(save_path, processed_image)\n",
    "\n",
    "print(\"‚úÖ Processamento conclu√≠do!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:anomalib.data.base.datamodule:No normal test images found. Sampling from training set using a split ratio of 0.20\n"
     ]
    }
   ],
   "source": [
    "# Import the datamodule\n",
    "from anomalib.data import Folder\n",
    "from anomalib.data.utils import TestSplitMode\n",
    "\n",
    "# Create the datamodule\n",
    "datamodule = Folder(\n",
    "    name=\"Rotulos_marca_M1\",\n",
    "    root=\"C:\\\\content\\\\processadas\",\n",
    "    normal_dir=\"rotulo_M1\",\n",
    "    test_split_mode=TestSplitMode.SYNTHETIC,\n",
    "    task=\"classification\",\n",
    ")\n",
    "\n",
    "# Setup the datamodule\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:anomalib.models.components.base.anomaly_module:Initializing Patchcore model.\n",
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/wide_resnet50_2.racm_in1k)\n",
      "INFO:timm.models._hub:[timm/wide_resnet50_2.racm_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "INFO:timm.models._builder:Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "INFO:anomalib.data.base.datamodule:No normal test images found. Sampling from training set using a split ratio of 0.20\n",
      "WARNING:anomalib.metrics.f1_score:F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead\n",
      "c:\\Users\\vitor\\anaconda3\\envs\\Anomaly_m1\\lib\\site-packages\\lightning\\pytorch\\core\\optimizer.py:183: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name                  | Type                     | Params | Mode \n",
      "---------------------------------------------------------------------------\n",
      "0 | model                 | PatchcoreModel           | 24.9 M | train\n",
      "1 | _transform            | Compose                  | 0      | train\n",
      "2 | normalization_metrics | MetricCollection         | 0      | train\n",
      "3 | image_threshold       | F1AdaptiveThreshold      | 0      | train\n",
      "4 | pixel_threshold       | F1AdaptiveThreshold      | 0      | train\n",
      "5 | image_metrics         | AnomalibMetricCollection | 0      | train\n",
      "6 | pixel_metrics         | AnomalibMetricCollection | 0      | train\n",
      "---------------------------------------------------------------------------\n",
      "24.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "24.9 M    Total params\n",
      "99.450    Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "174       Modules in eval mode\n",
      "c:\\Users\\vitor\\anaconda3\\envs\\Anomaly_m1\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "c:\\Users\\vitor\\anaconda3\\envs\\Anomaly_m1\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:420: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70c5e2e5f174b1696494c0791615293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vitor\\anaconda3\\envs\\Anomaly_m1\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:134: `training_step` returned `None`. If this was on purpose, ignore this warning...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd2488df527432197042a116aa58d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:anomalib.models.image.patchcore.lightning_model:Aggregating the embedding extracted from the training set.\n",
      "INFO:anomalib.models.image.patchcore.lightning_model:Applying core-set subsampling to get the embedding.\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#¬†Import the model and engine\n",
    "from anomalib.models import Patchcore\n",
    "from anomalib.engine import Engine\n",
    "\n",
    "# Create the model and engine\n",
    "model = Patchcore()\n",
    "engine = Engine(task=\"classification\")\n",
    "\n",
    "# Train a Patchcore model on the given datamodule\n",
    "engine.train(datamodule=datamodule, model=model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anomaly_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
